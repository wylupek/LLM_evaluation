{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## DeepEval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a1f04f39ab17b34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports and logging in"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "451df0d9de0d8718"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\filip\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import torch\n",
    "\n",
    "load_dotenv()\n",
    "login(os.getenv(\"HUGGINGFACE_API_KEY\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:53:28.105319100Z",
     "start_time": "2024-07-25T09:53:24.896470100Z"
    }
   },
   "id": "8504d05fe5ec6fb1",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Llama-3 8B"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0bacf35eb136d23"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "127c7c93a5104fe98f39a572e06064e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    device_map=\"auto\",\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:12.058192100Z",
     "start_time": "2024-07-25T09:53:28.099320300Z"
    }
   },
   "id": "6e74b4427dd75074",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing loaded model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6cf01c3e6531f28"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, shiver me timbers! Me be Captain Chat, the scurviest pirate chatbot to ever sail the seven seas... er, chat the digital seas! Me be here to swab the decks with ye, answerin' yer questions and tellin' tales of adventure and booty. So hoist the colors, me hearty, and let's set sail fer a swashbucklin' good time!\n"
     ]
    }
   ],
   "source": [
    "terminators_test = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "messages_test = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "input_ids_test = tokenizer.apply_chat_template(\n",
    "    messages_test,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "\n",
    "outputs_test = model.generate(\n",
    "    input_ids_test,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators_test,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "response_test = outputs_test[0][input_ids_test.shape[-1]:]\n",
    "print(tokenizer.decode(response_test, skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:15.625164500Z",
     "start_time": "2024-07-25T09:54:12.060192100Z"
    }
   },
   "id": "15de71dd18f0029b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a very short JSON file:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages_test = [\n",
    "    {\"role\": \"user\", \"content\": \"Generate very short JSON file.\"},\n",
    "]\n",
    "\n",
    "input_ids_test = tokenizer.apply_chat_template(\n",
    "    messages_test,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "outputs_test = model.generate(\n",
    "    input_ids_test,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators_test,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "response_test = outputs_test[0][input_ids_test.shape[-1]:]\n",
    "print(tokenizer.decode(response_test, skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:16.612099100Z",
     "start_time": "2024-07-25T09:54:15.623164400Z"
    }
   },
   "id": "73e20a9b098563bc",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Class for DeepEval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2df64017f6988727"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomLlama(DeepEvalBaseLLM):\n",
    "    def __init__(self, init_model, init_tokenizer):\n",
    "        self.model = init_model\n",
    "        self.tokenizer = init_tokenizer\n",
    "        self.terminators = [\n",
    "            init_tokenizer.eos_token_id,\n",
    "            init_tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "        ]\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        prompt = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            prompt,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=256,\n",
    "            eos_token_id=self.terminators,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        return tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Llama-3 8B\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:16.615610600Z",
     "start_time": "2024-07-25T09:54:16.610919400Z"
    }
   },
   "id": "bc5d886471012c09",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "custom_LLM = CustomLlama(init_model=model, init_tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:16.623408800Z",
     "start_time": "2024-07-25T09:54:16.613610100Z"
    }
   },
   "id": "7991354556953028",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two-tired!\n"
     ]
    }
   ],
   "source": [
    "print(custom_LLM.generate(\"Tell a joke.\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:17.307238400Z",
     "start_time": "2024-07-25T09:54:16.623408800Z"
    }
   },
   "id": "c94a69c86cc6f3ff",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DeepEval metrics\n",
    "#### Hallucination"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c6e7ac10e43d168"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33e3346680294b00af12391a10114a87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "The score is 0.00 because the actual output perfectly aligns with the provided context, indicating no hallucination.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import HallucinationMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual documents that you are passing as input to your LLM.\n",
    "context=[\"A man with blond-hair, and a brown shirt drinking out of a public water fountain.\"]\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "output=\"A blond drinking water in public.\"\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What was the blond doing?\",\n",
    "    actual_output=output,\n",
    "    context=context\n",
    ")\n",
    "metric = HallucinationMetric(threshold=0.5, model=custom_LLM)\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "# evaluate([test_case], [metric])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:20.335753300Z",
     "start_time": "2024-07-25T09:54:17.306237800Z"
    }
   },
   "id": "7f42e30f72eee19b",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Summarization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "259627faf0c728d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9fe474650ae488bb026ad1b458a365f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "The score is 0.33 because the summary fails to accurately represent the original text, introducing new information not present in the original text, and cannot answer certain questions that the original text can. The lack of contradictions in the original text suggests that the summary is not a faithful representation of the original text, and the score reflects this.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import SummarizationMetric\n",
    "\n",
    "# This is the original text to be summarized\n",
    "input_text = \"\"\"\n",
    "The 'coverage score' is calculated as the percentage of assessment questions\n",
    "for which both the summary and the original document provide a 'yes' answer. This\n",
    "method ensures that the summary not only includes key information from the original\n",
    "text but also accurately represents it. A higher coverage score indicates a\n",
    "more comprehensive and faithful summary, signifying that the summary effectively\n",
    "encapsulates the crucial points and details from the original content.\n",
    "\"\"\"\n",
    "\n",
    "# This is the summary, replace this with the actual output from your LLM application\n",
    "output = \"\"\"\n",
    "The coverage score quantifies how well a summary captures and\n",
    "accurately represents key information from the original text,\n",
    "with a higher score indicating greater comprehensiveness.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "test_case = LLMTestCase(input=input_text, actual_output=output)\n",
    "metric = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=custom_LLM,\n",
    "    assessment_questions=[\n",
    "        \"Is the coverage score based on a percentage of 'yes' answers?\",\n",
    "        \"Does the score ensure the summary's accuracy with the source?\",\n",
    "        \"Does a higher score mean a more comprehensive summary?\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:35.179449100Z",
     "start_time": "2024-07-25T09:54:20.335753300Z"
    }
   },
   "id": "69bd1d254a3bdd44",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Answer Relevancy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98de52fd5cf96e8d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6721ac84fc4349a88ac0383de323812f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "The score is 0.00 because the actual output provided irrelevant statements that are not directly related to the input question, such as 'If shoes don't fit' and 'you can refund them at no extra cost', which are not relevant to discussing the consequences of shoes not fitting.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "output = \"If shoes don't fit you can refund them at no extra cost.\"\n",
    "input_text = \"What if these shoes don't fit?\"\n",
    "\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.5,\n",
    "    model=custom_LLM,\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=input_text,\n",
    "    actual_output=output\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:42.417121700Z",
     "start_time": "2024-07-25T09:54:35.177448200Z"
    }
   },
   "id": "3cd3dcced40505b",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### G-Eval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "637bae1461eb42e2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd06910a6f434b91838ef4d24d5e6df2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "The Actual Output does not accurately reflect the expected outcome, considering the provided Input. The Input asks a specific question, but the Output provides a vague answer.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "correctness_metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    criteria=\"Determine whether the actual output is factually correct based on the expected output.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    # evaluation_steps=[\n",
    "    #     \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n",
    "    #     \"You should also heavily penalize omission of detail\",\n",
    "    #     \"Vague language, or contradicting OPINIONS, are OK\"\n",
    "    # ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=custom_LLM,\n",
    ")\n",
    "\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"The dog chased the cat up the tree, who ran up the tree?\",\n",
    "    actual_output=\"It depends, some might consider the cat, while others might argue the dog.\",\n",
    "    expected_output=\"The cat.\"\n",
    ")\n",
    "\n",
    "correctness_metric.measure(test_case)\n",
    "print(correctness_metric.score)\n",
    "print(correctness_metric.reason)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T09:54:47.138812700Z",
     "start_time": "2024-07-25T09:54:42.415121400Z"
    }
   },
   "id": "60f8c15a18d55814",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
